{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac8a0d05",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ‚Äì ASSIGNMENT 2\n",
    "\n",
    "# Jane Chinwuko\n",
    "# Batch number: DS2307\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dbeaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\omen\\anaconda3\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: idna in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\omen\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\omen\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\omen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\omen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\omen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\omen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\omen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\omen\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfcfab",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bb6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9471fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb2dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4499936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and input the job title\n",
    "job_title_input = driver.find_element(By.CLASS_NAME, \"form-control  \")\n",
    "job_title_input.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d83d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and input the location\n",
    "location_input = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location_input.send_keys(\"Bangalore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ef31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME, \"searchForm_btnWrap_advance__VYBHN\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99dc5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66267661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data for the first 10 job results\n",
    "# Scrape the first job title\n",
    "title_tags = driver.find_elements(By.XPATH, '/html/body/div[1]/div[1]/div[5]/div/div[1]//h2')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scrape the first job loction\n",
    "location_tags = driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# Scrape the first company name\n",
    "company_tags = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# Scrape the first experience required    \n",
    "experience_tags = driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    expn = i.text\n",
    "    experience_required.append(expn)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3972f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5c74ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title        Location  \\\n",
      "0                 Project Coordinator (Data Analyst)       Bangalore   \n",
      "1                         Data Analyst - Java/Python       Bangalore   \n",
      "2                            Hiring For Data Analyst  Bangalore\\n+14   \n",
      "3                                Senior Data Analyst       Bangalore   \n",
      "4                                       Data Analyst   Bangalore\\n+9   \n",
      "5                     Data Analyst Urgent Recruiment  Bangalore\\n+14   \n",
      "6  How relevant did you find the job search resul...       Bangalore   \n",
      "7                           Apply Now a Data Analyst       Bangalore   \n",
      "8                             Apply Now Data Analyst       Bangalore   \n",
      "9                            Needed for Data Analyst       Bangalore   \n",
      "\n",
      "                             Company_name   Experience  \n",
      "0                     futures and careers   2 to 4 Yrs  \n",
      "1  boyen haddin consulting and technol...   3 to 6 Yrs  \n",
      "2                kavya staffing solutions   0 to 4 Yrs  \n",
      "3           ara resources private limited   2 to 5 Yrs  \n",
      "4  ashutosh sabhashankar chaturvedi hi...  7 to 12 Yrs  \n",
      "5                       divya interprises   0 to 4 Yrs  \n",
      "6       deuglo infosystem private limited   1 to 2 Yrs  \n",
      "7       deuglo infosystem private limited   1 to 2 Yrs  \n",
      "8       deuglo infosystem private limited   1 to 2 Yrs  \n",
      "9       deuglo infosystem private limited   1 to 2 Yrs  \n"
     ]
    }
   ],
   "source": [
    "#Create the dataframe and display the result\n",
    "df = pd.DataFrame({'Title': job_title, 'Location': job_location, 'Company_name': company_name, 'Experience':experience_required})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614c2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961cd945",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter thelocation‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec573d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a91ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a397bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0530c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and input the job title\n",
    "job_title_input = driver.find_element(By.CLASS_NAME, \"form-control  \")\n",
    "job_title_input.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b91c3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and input the location\n",
    "location_input = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location_input.send_keys(\"Bangalore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4f8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME, \"searchForm_btnWrap_advance__VYBHN\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "391bc130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ffb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data for the first 10 job results\n",
    "# Scrape the first job title\n",
    "title_job = driver.find_elements(By.XPATH, '/html/body/div[1]/div[1]/div[5]/div/div[1]//h2')\n",
    "for i in title_job[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scrape the first job loction\n",
    "location_job  = driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_job[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# Scrape the first company name\n",
    "company_job = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_job[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e38c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3defe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title        Location  \\\n",
      "0                          Hiring For Data Scientist  Bangalore\\n+17   \n",
      "1                          Hiring For Data Scientist  Bangalore\\n+17   \n",
      "2                                     Data Scientist       Bangalore   \n",
      "3                  Data Scientist Urgent Recruitment  Bangalore\\n+14   \n",
      "4                        Required for Data Scientist       Bangalore   \n",
      "5                       Urgently need Data Scientist   Bangalore\\n+8   \n",
      "6  How relevant did you find the job search resul...       Bangalore   \n",
      "7                           Data scientist Bangalore       Bangalore   \n",
      "8                                     Data Scientist  Bangalore\\n+15   \n",
      "9                          Hiring For Data Scientist   Bangalore\\n+8   \n",
      "\n",
      "                             Company_name  \n",
      "0                kavya staffing solutions  \n",
      "1                kavya staffing solutions  \n",
      "2                     skyleaf consultants  \n",
      "3                       divya interprises  \n",
      "4       deuglo infosystem private limited  \n",
      "5       deuglo infosystem private limited  \n",
      "6  seven geomax consulting private lim...  \n",
      "7  employberry consultants hiring for ...  \n",
      "8                    niharika enterprises  \n",
      "9       deuglo infosystem private limited  \n"
     ]
    }
   ],
   "source": [
    "#Create the dataframe and display the result\n",
    "df = pd.DataFrame({'Title': job_title, 'Location': job_location, 'Company_name': company_name})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d67012c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46a7b4",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter.\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8091d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac00fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a97de896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ba7dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and input the job title\n",
    "job_title_input = driver.find_element(By.CLASS_NAME, \"form-control  \")\n",
    "job_title_input.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255592e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME, \"searchForm_btnWrap_advance__VYBHN\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2741cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and select the location filter\n",
    "location_filter = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div/ul/li[1]\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff131b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select delhi in location filter\n",
    "delhi_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[8]\")\n",
    "delhi_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d143cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7452fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and select the salary filter\n",
    "salary_filter = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div/ul/li[3]/button\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a211944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 3-5 lakhs in the salary filter\n",
    "lakh_input = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label\")\n",
    "lakh_input.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6adf6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click the search button\n",
    "search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39309d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "946a2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape job title,location,company name nd experience required for the first 10 job results\n",
    "for pages in range(0,1):\n",
    "    title_tags = driver.find_elements(By.XPATH, '/html/body/div[1]/div[1]/div[5]/div/div[1]//h2')\n",
    "    for i in title_tags[0:10]:\n",
    "        title = i.text\n",
    "        job_title.append(title)\n",
    "    \n",
    "\n",
    "    location_tags = driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "    for i in location_tags[0:10]:\n",
    "        location = i.text\n",
    "        job_location.append(location)\n",
    "    \n",
    "\n",
    "    company_tags = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "    for i in company_tags[0:10]:\n",
    "        company = i.text\n",
    "        company_name.append(company)\n",
    "    \n",
    "    \n",
    "    experience_tags = driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "    for i in experience_tags[0:10]:\n",
    "        exp = i.text\n",
    "        experience_required.append(exp)\n",
    "    \n",
    "    next_button = driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7dfc490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5578a196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title   Location  \\\n",
      "0                                     Data Scientist  Delhi\\n+6   \n",
      "1                                     Data Scientist      Delhi   \n",
      "2                                     Data Scientist  Delhi\\n+6   \n",
      "3                                     Data Scientist  Delhi\\n+4   \n",
      "4       for _GCP Data Engineer/Lead/Architect- Delhi      Delhi   \n",
      "5       for _GCP Data Engineer/Lead/Architect- Delhi      Delhi   \n",
      "6  How relevant did you find the job search resul...      Delhi   \n",
      "7  Req. For Data Scientist -Reputed Data Analytic...      Delhi   \n",
      "8      For Senior Data Scientist-Reputed IT Industry      Delhi   \n",
      "9                            Req. now Data Scientist      Delhi   \n",
      "\n",
      "                    Company_name  Experience  \n",
      "0                quiscon biotech  0 to 3 Yrs  \n",
      "1            skyleaf consultants  3 to 6 Yrs  \n",
      "2                quiscon biotech   0 to 1 Yr  \n",
      "3  acme services private limited  3 to 5 Yrs  \n",
      "4          nina s hr consultancy  2 to 3 Yrs  \n",
      "5          nina s hr consultancy  2 to 3 Yrs  \n",
      "6              seven consultancy  2 to 6 Yrs  \n",
      "7              seven consultancy  4 to 8 Yrs  \n",
      "8              seven consultancy  3 to 5 Yrs  \n",
      "9            skyleaf consultants  3 to 6 Yrs  \n"
     ]
    }
   ],
   "source": [
    "#Create the dataframe and display the result\n",
    "df = pd.DataFrame({'Title': job_title, 'Location': job_location, 'Company_name': company_name, 'Experience':experience_required})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59ff8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170ce7f",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. ProductDescription\n",
    "8. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter ‚Äúsunglasses‚Äù in the search fieldwhere ‚Äúsearch for products, brands and more‚Äù is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the ‚ÄúNext‚Äù Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00c2e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "177459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fa6afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd249dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for sunglasses in search box\n",
    "sunglasses=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "sunglasses.send_keys('sunglasses')\n",
    "sunglasses.send_keys(Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab4aebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b39fd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for results to load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8b0a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for brand, product description and price\n",
    "# Loop through multiple pages\n",
    "for j in range(0,3):\n",
    "    brands=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")[0:100]\n",
    "    for i in brands:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    Product_desc=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")[0:100]\n",
    "    for i in Product_desc:\n",
    "        product_description.append(i.text)   \n",
    "        \n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")[0:100]\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    next_click=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\") \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8a6c871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 105 117\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ddd846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data for 100 sunglasses\n",
    "brand = brand[0:100]\n",
    "prod_description = product_description[0:100]\n",
    "price = price[0:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb8902ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Prod_desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection, Polarized Over-sized Sunglasses...</td>\n",
       "      <td>‚Çπ899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>‚Çπ379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>‚Çπ204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>‚Çπ239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>‚Çπ179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Night Vision Retro Square Sunglasses (60)</td>\n",
       "      <td>‚Çπ495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>‚Çπ294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (56)</td>\n",
       "      <td>‚Çπ3,740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>‚Çπ283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>Night Vision, UV Protection, Polarized Wrap-ar...</td>\n",
       "      <td>‚Çπ1,037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                          Prod_desc   Price\n",
       "0   VINCENT CHASE  UV Protection, Polarized Over-sized Sunglasses...    ‚Çπ899\n",
       "1    Singco India  Riding Glasses, UV Protection Clubmaster, Wayf...    ‚Çπ379\n",
       "2            SRPM             UV Protection Wayfarer Sunglasses (50)    ‚Çπ204\n",
       "3          PIRASO           UV Protection Clubmaster Sunglasses (54)    ‚Çπ239\n",
       "4       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...    ‚Çπ179\n",
       "..            ...                                                ...     ...\n",
       "95      ROYAL SON          Night Vision Retro Square Sunglasses (60)    ‚Çπ495\n",
       "96   Singco India     Polarized, UV Protection Round Sunglasses (50)    ‚Çπ294\n",
       "97    john jacobs          UV Protection Rectangular Sunglasses (56)  ‚Çπ3,740\n",
       "98      Rich Club         UV Protection Retro Square Sunglasses (54)    ‚Çπ283\n",
       "99        ROADWAY  Night Vision, UV Protection, Polarized Wrap-ar...  ‚Çπ1,037\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the dataframe and display the result\n",
    "df=pd.DataFrame({'Brand':brand,'Prod_desc':prod_description,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bbfab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7cc77",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c049130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "335b7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1481ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the website\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "749fefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "pages=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]\n",
    "Rating=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1391eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for results to load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aace3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape the url for 10 pages to get 100 reviews\n",
    "navigation_1 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in navigation_1:\n",
    "    pages.append(i.get_attribute('href'))\n",
    "navigation_2 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M']\")\n",
    "for i in navigation_2:\n",
    "    pages.append(i.get_attribute('href'))\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "for j in pages:\n",
    "    driver.get(j)\n",
    "    #scrape the number of Rating in the review\n",
    "    for k in driver.find_elements(By.XPATH,\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        Rating.append(k.text)\n",
    "    #scrape the summary of the reviews\n",
    "    for l in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "        Review_summary.append(l.text)\n",
    "    #scrape the full reviews\n",
    "    for m in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        Full_review.append(m.text)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c3d18f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af7e0581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Best phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Perfect iPhone on this budget!! Camera and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Battery backup is extraordinary, camera is dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>iPhone is delivered on time. Display is great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating     Review Summary  \\\n",
       "0       5  Terrific purchase   \n",
       "1       5     Classy product   \n",
       "2       5           Terrific   \n",
       "3       5     Classy product   \n",
       "4       5          Wonderful   \n",
       "..    ...                ...   \n",
       "95      5          Brilliant   \n",
       "96      5          Brilliant   \n",
       "97      5   Perfect product!   \n",
       "98      5  Worth every penny   \n",
       "99      5     Classy product   \n",
       "\n",
       "                                          Full Review  \n",
       "0                                   Value for money üòç  \n",
       "1                                        Photos super  \n",
       "2                                      Very very good  \n",
       "3   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "4                              This is amazing at all  \n",
       "..                                                ...  \n",
       "95                                         Best phone  \n",
       "96  Perfect iPhone on this budget!! Camera and the...  \n",
       "97  Battery backup is extraordinary, camera is dec...  \n",
       "98  iPhone is delivered on time. Display is great ...  \n",
       "99                 Outstanding performance this phone  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the dataframe and display the result\n",
    "df=pd.DataFrame({'Rating':Rating,'Review Summary':Review_summary,'Full Review':Full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab01eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79774905",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find whenyou visit flipkart.com and search for ‚Äúsneakers‚Äù inthe\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9686cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c271b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88886d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3718ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for sneakers in the web page\n",
    "sneakers=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "sneakers.send_keys('sneakers')\n",
    "sneakers.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd3f0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a4e1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for brand, price and product description \n",
    "#looping 4 page to scrap data\n",
    "for page in range(0,4):\n",
    "    \n",
    "    brands=driver.find_elements(By.CLASS_NAME,'_2WkVRV')\n",
    "    for i in brands:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]')\n",
    "    for i in desc:\n",
    "        description.append(i.text)\n",
    "    #scraping the list of buttons in the page   \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53d4e5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 160 160\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(brand),len(description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef8f5d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Prod_desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Rebound LayUp SL Sneakers For Men</td>\n",
       "      <td>‚Çπ2,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>jootiyapa</td>\n",
       "      <td>JOOTIYAPA PREMIUM SNEAKERS FOR MEN Sneakers Fo...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ1,399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                          Prod_desc   Price\n",
       "0          BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men    ‚Çπ499\n",
       "1   WHITE WALKERS  Stylish & Trending Outdoor Walking Comfortable...    ‚Çπ599\n",
       "2        Nobelite                                   Sneakers For Men    ‚Çπ299\n",
       "3          BRUTON               Modern Trendy Shoes Sneakers For Men    ‚Çπ379\n",
       "4        Nobelite                                   Sneakers For Men    ‚Çπ299\n",
       "..            ...                                                ...     ...\n",
       "95           PUMA                  Rebound LayUp SL Sneakers For Men  ‚Çπ2,399\n",
       "96  WHITE WALKERS  Stylish & Trending Outdoor Walking Comfortable...    ‚Çπ599\n",
       "97       RapidBox                                   Sneakers For Men    ‚Çπ695\n",
       "98      jootiyapa  JOOTIYAPA PREMIUM SNEAKERS FOR MEN Sneakers Fo...    ‚Çπ499\n",
       "99       RED TAPE                                   Sneakers For Men  ‚Çπ1,399\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe for 100 items and display results\n",
    "df=pd.DataFrame({'Brand':brand[0:100],'Prod_desc':description[0:100],'Price':price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7733f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "##close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b62c3",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then\n",
    "set CPU Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ef144f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5d7428da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5d89cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "84e80431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for laptops in the web page\n",
    "laptop=driver.find_element(By.XPATH,\"//div[@class='nav-search-field ']//input\")\n",
    "laptop.send_keys('Laptop')\n",
    "laptop.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a160843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to filter i7 CPu-\n",
    "cpu_filter1=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[7]/ul[7]/span[11]/li/span/a/span\")\n",
    "cpu_filter1.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fff8c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for results to load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0357db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "Title=[]\n",
    "price=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2e9ca38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping through pages to scrap data\n",
    "for webpage in range(0,1):\n",
    "    page_title=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "    for i in page_title[0:10]:\n",
    "        titles = i.text\n",
    "        Title.append(titles) \n",
    "        \n",
    "    item_prices=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "    for i in item_prices[0:10]:\n",
    "        prices = i.text\n",
    "        price.append(prices)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71f53c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the ratings for each laptop\n",
    "item_rating=driver.find_elements(By.XPATH,\"//div[@class='a-row a-size-small']/span\")\n",
    "for i in item_rating:\n",
    "    Rating.append(i.get_attribute(\"aria-label\")) \n",
    "stars=[]\n",
    "for i in range(0,len(Rating))[0:20]:\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        stars.append(Rating[i][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae905fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(Title),len(price),len(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a3afd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>70,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1,15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>86,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Nitro 5 12th Gen Intel Core i7-12650H Gam...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell Vostro 5630 13th Gen Laptop,Intel i7-1355...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Inspiron 5630 13th Gen Laptop, Intel Core...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...     4.5    70,990\n",
       "1  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...     4.0    64,990\n",
       "2  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...     4.4  1,15,990\n",
       "3  Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...     3.3    86,249\n",
       "4  Acer Nitro 5 12th Gen Intel Core i7-12650H Gam...     4.1    99,990\n",
       "5  Dell Vostro 5630 13th Gen Laptop,Intel i7-1355...     4.6    89,990\n",
       "6  Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...     3.3    62,990\n",
       "7  HP Victus Gaming Latest 12th Gen Intel Core i7...     4.1    87,990\n",
       "8  Dell Inspiron 5630 13th Gen Laptop, Intel Core...     3.6    89,990\n",
       "9  ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...     4.5    89,990"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe and display results\n",
    "df=pd.DataFrame({'Title':Title,'Ratings':stars,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65a03c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349b003",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9b22dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "08489616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ec22387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3add05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Top Quotes tab\n",
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a2dd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "Quote=[]\n",
    "Author=[]\n",
    "Type_of_quotes=[]\n",
    "\n",
    "#fetching the details\n",
    "quote_details=[i.text.split('\\n') for i in driver.find_elements(By.XPATH,\"//div[@class='wrap-block']\")]\n",
    "\n",
    "#Looping through the quote details to fetch the different features and append to the list created\n",
    "for i in quote_details:\n",
    "    Quote.append(i[0])\n",
    "    Author.append(i[1])\n",
    "    Type_of_quotes.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "af455901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quote                Author  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                              Type of Quotes  \n",
       "0   Essence, Deep Thought, Transcendentalism  \n",
       "1                  Inspiration, Past, Trying  \n",
       "2                        Country, Peace, War  \n",
       "3         Inspirational, Motivational, Death  \n",
       "4               4th Of July, Food, Patriotic  \n",
       "..                                       ...  \n",
       "95                    Music, Sports, Hunting  \n",
       "96             Trust, Encouraging, Uplifting  \n",
       "97              Inspirational, Funny, Change  \n",
       "98                      Success, God, Mother  \n",
       "99       Inspirational, Motivational, Change  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe and display results\n",
    "df=pd.DataFrame({'Quote':Quote,'Author':Author,'Type of Quotes':Type_of_quotes })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a84bf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6831f7",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "446dca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5da47865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "93b7d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "671a6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the GK option tab\n",
    "gk_click = driver.find_element(By.XPATH, \"/html/body/div/header/nav/div/div/div[3]/ul/li[3]/a\")\n",
    "gk_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fb6436e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the List of all Prime Ministers of India\n",
    "President_click = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "President_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3073e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists for the features to be scraped from the website\n",
    "Name = []\n",
    "Born_Dead = []\n",
    "Terms_of_office = []\n",
    "Remarks = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dcb92939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the Name, Born-Dead,Term of office, and Remarks\n",
    "names = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "for i in names:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "04fe3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the Born-Dead\n",
    "born_dead = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for i in born_dead:\n",
    "    Born_Dead.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78c52328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the Term of office\n",
    "terms_of_office = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[4]')\n",
    "for i in terms_of_office:\n",
    "    title = i.text\n",
    "    Terms_of_office.append(i.text.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bf6a4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the Remarks\n",
    "remarks = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for i in remarks:\n",
    "    Remarks.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a074ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19 19 19\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(Name),len(Born_Dead),len(Terms_of_office),len(Remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "28e2701c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 196416 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904‚Äì1966)</td>\n",
       "      <td>9 June 1964 to 11 January 19661 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 196613 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>24 January 1966 to 24 March 197711 years, 59 days</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896‚Äì1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902‚Äì1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>14 January 1980 to 31 October 19844 years, 291...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944‚Äì1991)</td>\n",
       "      <td>31 October 1984 to 2 December 19895 years, 32 ...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931‚Äì2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927‚Äì2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921‚Äì2004)</td>\n",
       "      <td>21 June 1991 to 16 May 19964 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 199616 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919‚Äì2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Names     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889‚Äì1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904‚Äì1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917‚Äì1984)   \n",
       "5                 Morarji Desai   (1896‚Äì1995)   \n",
       "6                  Charan Singh   (1902‚Äì1987)   \n",
       "7                 Indira Gandhi   (1917‚Äì1984)   \n",
       "8                  Rajiv Gandhi   (1944‚Äì1991)   \n",
       "9                   V. P. Singh   (1931‚Äì2008)   \n",
       "10              Chandra Shekhar   (1927‚Äì2007)   \n",
       "11          P. V. Narasimha Rao   (1921‚Äì2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919‚Äì2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "18                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term of office  \\\n",
       "0     15 August 1947 to 27 May 196416 years, 286 days   \n",
       "1                  27 May 1964 to 9 June 1964,13 days   \n",
       "2      9 June 1964 to 11 January 19661 year, 216 days   \n",
       "3           11 January 1966 to 24 January 196613 days   \n",
       "4   24 January 1966 to 24 March 197711 years, 59 days   \n",
       "5     24 March 1977 to  28 July 1979 2 year, 126 days   \n",
       "6             28 July 1979 to 14 January 1980170 days   \n",
       "7   14 January 1980 to 31 October 19844 years, 291...   \n",
       "8   31 October 1984 to 2 December 19895 years, 32 ...   \n",
       "9         2 December 1989 to 10 November 1990343 days   \n",
       "10           10 November 1990 to 21 June 1991223 days   \n",
       "11       21 June 1991 to 16 May 19964 years, 330 days   \n",
       "12                  16 May 1996 to 1 June 199616 days   \n",
       "13               1 June 1996 to 21 April 1997324 days   \n",
       "14            21 April 1997 to 19 March 1998 332 days   \n",
       "15      19 March 1998 to 22 May 2004 6 years, 64 days   \n",
       "16      22 May 2004 to 26 May 2014   10 years, 4 days   \n",
       "17                                 26 May 2014 - 2019   \n",
       "18                             30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from South India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  \n",
       "18  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe and display results\n",
    "df=pd.DataFrame({\"Names\":Name,\"Born-Dead\":Born_Dead,\"Term of office\":Terms_of_office,\n",
    "                \"Remarks\":Remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "634dbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2b950",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ‚Äô50 most expensive cars‚Äô\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a6153213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1b4e7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()  # Change this to your WebDriver of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c0958554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Shine.com website\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e0f7adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for 50 Most Expensive Cars In The World\n",
    "cars_search=driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "cars_search.send_keys(\"50 Most Expensive Cars In The World\")\n",
    "cars_search.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "33fd401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the 50 Most Expensive Cars In The World tab\n",
    "car_exp=driver.find_element(By.XPATH,\"/html/body/div[10]/div[9]/div/div[1]/div/div/div[1]/div/div[1]/h3/a\")\n",
    "car_exp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e2ce6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list\n",
    "exp_cars = []\n",
    "car_prices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7d5f44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for the Car names and their Prices\n",
    "names_cars = driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in names_cars:\n",
    "    exp_cars.append(i.text)\n",
    "exp_cars.pop()\n",
    "\n",
    "prices_cars = driver.find_elements(By.XPATH,\"//strong\")\n",
    "for j in prices_cars:\n",
    "    car_prices.append(j.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b32f9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "#View the length of the features\n",
    "print(len(exp_cars),len(car_prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e36b7196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR NAME</th>\n",
       "      <th>PRICE OF CAR($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aston Martin Valour</td>\n",
       "      <td>Price: $1.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ferrari Daytona SP3</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zenvo Aurora</td>\n",
       "      <td>Price: $2.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pininfarina B95 Speedster</td>\n",
       "      <td>Price: $4.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>777 Hypercar</td>\n",
       "      <td>Price: $7.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Chiron Profil√©e</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce La Rose Noire Droptail</td>\n",
       "      <td>Price: $30 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              CAR NAME              PRICE OF CAR($)\n",
       "0                  Aston Martin Valour          Price: $1.5 Million\n",
       "1                         McLaren Elva          Price: $1.7 Million\n",
       "2                          Czinger 21C          Price: $1.7 Million\n",
       "3                        Ferrari Monza          Price: $1.7 Million\n",
       "4                   Gordon Murray T.33          Price: $1.7 Million\n",
       "5                    Koenigsegg Gemera          Price: $1.7 Million\n",
       "6                          Zenvo TSR-S          Price: $1.7 Million\n",
       "7                   Hennessey Venom F5          Price: $1.8 Million\n",
       "8                      Bentley Bacalar          Price: $1.9 Million\n",
       "9        Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
       "10              Bentley Mulliner Batur          Price: $2.0 Million\n",
       "11                        Deus Vayanne          Price: $2.0 Million\n",
       "12                         SSC Tuatara          Price: $2.0 Million\n",
       "13                         Lotus Evija          Price: $2.1 Million\n",
       "14                 Aston Martin Vulcan          Price: $2.3 Million\n",
       "15                          Delage D12          Price: $2.3 Million\n",
       "16                 Ferrari Daytona SP3          Price: $2.3 Million\n",
       "17                   McLaren Speedtail          Price: $2.3 Million\n",
       "18                        Rimac Nevera          Price: $2.4 Million\n",
       "19                       Pagani Utopia          Price: $2.5 Million\n",
       "20                Pininfarina Battista          Price: $2.5 Million\n",
       "21                  Gordon Murray T.50          Price: $2.6 Million\n",
       "22                Lamborghini Countach          Price: $2.6 Million\n",
       "23            Mercedes-AMG Project One          Price: $2.7 Million\n",
       "24                        Zenvo Aurora          Price: $2.8 Million\n",
       "25                 Aston Martin Victor          Price: $3.0 Million\n",
       "26         Hennessey Venom F5 Roadster                 $3.0 Million\n",
       "27                    Koenigsegg Jesko          Price: $3.0 Million\n",
       "28               Aston Martin Valkyrie          Price: $3.2 Million\n",
       "29           W Motors Lykan Hypersport          Price: $3.4 Million\n",
       "30                       McLaren Solus                 $3.5 Million\n",
       "31                    Lamborghini Sian          Price: $3.6 million\n",
       "32                    Koenigsegg CC850          Price: $3.7 Million\n",
       "33     Bugatti Chiron Super Sport 300+          Price: $3.9 Million\n",
       "34                  Lamborghini Veneno          Price: $4.5 Million\n",
       "35                      Bugatti Bolide          Price: $4.7 Million\n",
       "36           Pininfarina B95 Speedster          Price: $4.8 Million\n",
       "37                     Bugatti Mistral          Price: $5.0 Million\n",
       "38                 Pagani Huayra Imola          Price: $5.4 Million\n",
       "39                        Bugatti Divo          Price: $5.8 Million\n",
       "40                 SP Automotive Chaos          Price: $6.4 Million\n",
       "41                    Pagani Codalunga          Price: $7.4 Million\n",
       "42                        777 Hypercar          Price: $7.5 Million\n",
       "43            Mercedes-Maybach Exelero          Price: $8.0 Million\n",
       "44                  Bugatti Centodieci          Price: $9.0 Million\n",
       "45             Bugatti Chiron Profil√©e         Price: $10.8 Million\n",
       "46                Rolls-Royce Sweptail         Price: $12.8 Million\n",
       "47            Bugatti La Voiture Noire         Price: $13.4 Million\n",
       "48              Rolls-Royce Boat Tail*  Price: $28.0 Million (est.)\n",
       "49  Rolls-Royce La Rose Noire Droptail    Price: $30 Million (est.)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe and display results\n",
    "df=pd.DataFrame({\"CAR NAME\":exp_cars,\"PRICE OF CAR($)\":car_prices})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ce25285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d2ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
